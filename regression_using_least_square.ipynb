{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import moduel\n",
    "import numpy as np\n",
    "import copy, math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(2290) #400132290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "def func(x):\n",
    "    return np.sin(4 * np.pi * x + np.pi/2)\n",
    "\n",
    "def generate_data(p):    \n",
    "    #generate sets\n",
    "    X_train = np.linspace(0.,1.,p)\n",
    "    X_valid = np.linspace(0.,1.,p*10)\n",
    "    #this is the label y, this this case it is t = sin(4*pi*x)\n",
    "    # t_train = func(X_train) + 0.3*np.random.randn(12)\n",
    "    # t_valid = func(X_valid) + 0.3*np.random.randn(120)\n",
    "\n",
    "    mean = 0\n",
    "    variance = 0.0625\n",
    "    # noise = np.random.normal(mean, np.sqrt(variance), size=(10,))\n",
    "    t_train = func(X_train) + np.random.normal(mean, np.sqrt(variance), size=(p,))\n",
    "    t_valid = func(X_valid) + np.random.normal(mean, np.sqrt(variance), size=(p*10,))\n",
    "    \n",
    "    return X_train,X_valid,t_train,t_valid\n",
    "\n",
    "def generate_matrix(x_train,t_train,x_valid,t_valid,exp):\n",
    "    xx_train = x_train[:,np.newaxis] ** [i for i in range(exp+1)]\n",
    "    xx_valid = x_valid[:,np.newaxis] ** [i for i in range(exp+1)]\n",
    "\n",
    "    tt_train = t_train[:,np.newaxis]\n",
    "    tt_valid = t_valid[:,np.newaxis]\n",
    "    # tt_train = np.array(tt_train)\n",
    "    # tt_valid = np.array(tt_valid)\n",
    "\n",
    "    return xx_train,xx_valid,tt_train,tt_valid\n",
    "\n",
    "#def apply_scaling():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model\n",
    "def train(X, t_train):\n",
    "    #w = (x^T * x)^-1 * (x^T * t)\n",
    "    w = np.linalg.inv(X.T @ X) @ (X.T @ t_train)\n",
    "    return w\n",
    "\n",
    "def train_regulation(X,t_train,B):\n",
    "    w = np.linalg.inv(X.T @ X + B) @ (X.T @ t_train)\n",
    "    return w\n",
    "\n",
    "def pred(X, w):\n",
    "    pred = (w * X).sum(axis=1, keepdims=True)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc error\n",
    "def calc_error(w,x_train,t_train,x_valid,t_valid):\n",
    "    # pred : w*x = y\n",
    "    # (y - t)^T (y - t) N\n",
    "    training_error = np.sum(np.square( (pred(x_train,w)- t_train) )) / t_train.shape[0]\n",
    "    valid_error = np.sum(np.square( (pred(x_valid,w)- t_valid) )) / t_valid.shape[0]\n",
    "\n",
    "    return training_error, valid_error\n",
    "\n",
    "def calc_error_regulation(w, x_train, t_train, x_valid, t_valid, lamda):\n",
    "    training_error, valid_error = calc_error(w, x_train, t_train, x_valid, t_valid)\n",
    "    training_error += lamda * np.sum(np.square(w))\n",
    "    valid_error += lamda * np.sum(np.square(w))\n",
    "\n",
    "    return training_error,valid_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "def plot_data(idx, t_pred, x_train, t_train, x_valid, t_valid, reg=False):\n",
    "    # create a new figure per model\n",
    "    fig = plt.figure(idx)\n",
    "    fig.suptitle(f\"{'Lambda=' if reg else 'Degree '}{idx}\")\n",
    "\n",
    "    # plot the training and validation data\n",
    "    plt.plot(x_train, t_train, '.', color=\"blue\", label=\"Training data\", mfc=\"none\")\n",
    "    plt.plot(x_valid, t_valid, '.', color=\"red\", label=\"Validation data\", mfc=\"none\")\n",
    "\n",
    "    # plot the model function and the true function\n",
    "    plt.plot(x_valid, func(x_valid), color=\"black\", label=\"f_true\")\n",
    "    plt.plot(x_valid, t_pred, color=\"lightgreen\", label=\"f_pred\")\n",
    "\n",
    "    # label the axies\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"t\")\n",
    "    \n",
    "    # show the figure\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "def plot_error_curves(x_train, t_train, t_valid):\n",
    "    # create a new figure per model\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(f\"Errors\")\n",
    "\n",
    "    # plot the training and validation data\n",
    "    plt.plot(x_train, t_train, '-', color=\"blue\", label=\"Training data\", mfc=\"none\")\n",
    "    plt.plot(x_train, t_valid, '-', color=\"red\", label=\"Validation data\", mfc=\"none\")\n",
    "\n",
    "    # show the figure\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 12\n",
    "x_train,x_valid,t_train,t_valid = generate_data(p)\n",
    "ans = {\n",
    "    \"M\": [ i for i in range(0,p)],\n",
    "    \"training_error\" : [],\n",
    "    \"valid_error\" : []\n",
    "}\n",
    "\n",
    "\n",
    "for exp in ans[\"M\"]:\n",
    "\n",
    "    xx_train,xx_valid,tt_train,tt_valid = generate_matrix(x_train,t_train,x_valid,t_valid,exp)\n",
    "    # print(xx_train.shape)\n",
    "    # print(xx_valid.shape)\n",
    "    # print(tt_train.shape)\n",
    "    # print(tt_valid.shape)\n",
    "    #print(xx_train)\n",
    "    w = train(xx_train,t_train)\n",
    "    print(w)\n",
    "    train_error, valid_error = calc_error(w,xx_train,tt_train,xx_valid,tt_valid)\n",
    "    print(f\"Degree {exp}: training error = {train_error:22}, validation error = {valid_error}\")\n",
    "    ans[\"training_error\"].append(train_error)\n",
    "    ans[\"valid_error\"].append(valid_error)\n",
    "    plot_data(exp, pred(w, xx_valid), x_train, t_train, x_valid, t_valid)\n",
    "\n",
    "print(f\"The lowest training error was at degree {ans['M'][np.argmin(ans['training_error'])]} and the \"\n",
    "          f\"lowest validation error was at degree {ans['M'][np.argmin(ans['valid_error'])]}\")\n",
    "\n",
    "print(xx_train[-1,:])\n",
    "#apply regulation\n",
    "xx_train = np.delete(xx_train,0,1)\n",
    "xx_valid = np.delete(xx_valid,0,1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "xx_train = sc.fit_transform(xx_train)\n",
    "xx_valid = sc.transform(xx_valid)\n",
    "xx_train = np.c_[np.ones(t_train.shape[0]), xx_train]\n",
    "xx_valid = np.c_[np.ones(t_valid.shape[0]), xx_valid]\n",
    "regulation = {\n",
    "    \"lamda\" : np.exp([i for i in range(-100,-1)]).tolist(),\n",
    "    \"training_error\" : [],\n",
    "    \"valid_error\" : [],\n",
    "    \"w\" : []\n",
    "}\n",
    "\n",
    "for lamda in regulation[\"lamda\"]:\n",
    "    #create lambda\n",
    "    B = np.zeros((p,p))\n",
    "    np.fill_diagonal(B, lamda * t_train.shape[0])\n",
    "\n",
    "    w = train_regulation(xx_train,t_train,B)\n",
    "    regulation[\"w\"].append(w)\n",
    "    train_error, valid_error = calc_error_regulation(w,xx_train,tt_train,xx_valid,tt_valid,lamda)\n",
    "    \n",
    "    #print(f\"lamda: {lamda}: training error = {train_error:22}, validation error = {valid_error}\")\n",
    "    regulation[\"training_error\"].append(train_error) \n",
    "    regulation[\"valid_error\"].append(valid_error)\n",
    "\n",
    "lowest_valid_error = np.argmin(regulation[\"valid_error\"])\n",
    "\n",
    "lambda1 = regulation['lamda'][lowest_valid_error]\n",
    "lambda2 = regulation['lamda'][-5]\n",
    "\n",
    "print(f\"The lowest regularised validation error was at constant {lambda1}\")\n",
    "\n",
    "plot_data(lambda1, pred(regulation[\"w\"][lowest_valid_error], xx_valid), x_train, t_train, x_valid,\n",
    "              t_valid, reg=True)\n",
    "plot_data(lambda2, pred(regulation[\"w\"][-4], xx_valid), x_train, t_train, x_valid, t_valid,\n",
    "              reg=True)\n",
    "\n",
    "plot_error_curves(ans[\"M\"],ans[\"training_error\"],ans[\"valid_error\"])\n",
    "print(ans[\"training_error\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
